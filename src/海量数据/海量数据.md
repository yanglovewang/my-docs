---
title: 海量数据
icon: fab fa-markdown
order: 3
category:
  - 使用指南
tag:
  - Markdown
---

<a name="Xtj5r"></a>

## 问题 1：海量日志数据，统计出某日访问百度次数最多的那个 IP

解决方式：<br />IP 地址最多有 2^32 = 4G 种取值情况，所以不能完全加载到内存中进行处理，采用 hash 分解+ 分而治之 + 归并 方式：<br />（1）按照 IP 地址的 Hash(IP)%1024 值，把海量 IP 日志分别存储到 1024 个小文件中。这样，每个小文件最多包含 4MB 个 IP 地址；<br />（2）对于每一个小文件，构建一个 IP 为 key，出现次数为 value 的 Hash map，同时记录当前出现次数最多的那个 IP 地址<br />（3）然后再在这 1024 组最大的 IP 中，找出那个频率最大的 IP
<a name="akxAQ"></a>

## 问题 2：有一个 1G 大小的一个文件，里面每一行是一个词，词的大小不超过 16 字节，内存限制大小是 1M。返回频数最高的 100 个词。

解决思想： hash 分解+ 分而治之 + 归并<br />（1）顺序读文件中，对于每个词 x，按照 hash(x)/(1024\*4) 存到 4096 个小文件中。这样每个文件大概是 250k 左右。如果其中的有的文件超过了 1M 大小，还可以按照 hash 继续往下分，直到分解得到的小文件的大小都不超过 1M。<br />（2）对每个小文件，可以采用 trie 树/hashmap 统计每个文件中出现的词以及相应的频率，使用 100 个节点的小顶堆取出出现频率最大的 100 个词，并把 100 个词及相应的频率存入文件。这样又得到了 4096 个文件。<br />（3）下一步就是把这 4096 个文件进行归并的过程了，内存里面用一个 size=100 的小顶堆，加载遍历每 4096 个文件的 top100，排序规则是针对词频进行排序，如果某一个单词的词频小于堆顶元素的词频，直接看下一个单词，如果大于堆顶元素的词频，那个弹出堆顶元素，把该单词加载进去。<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1635081/1687064581924-baab1d4c-4231-4818-8725-d1beb39fdd83.png#averageHue=%23fefdfc&clientId=u492e267b-d925-4&from=paste&id=u347fce12&originHeight=416&originWidth=948&originalType=url&ratio=0.800000011920929&rotation=0&showTitle=false&status=done&style=none&taskId=uff929d33-c8c0-4328-8475-c2d26422105&title=)
<a name="DuV4W"></a>

## 问题 3：有 a、b 两个文件，各存放 50 亿个 url，每个 url 各占 64 字节，内存限制 是 4G，让你找出 a、b 文件共同的 url？

![image.png](https://cdn.nlark.com/yuque/0/2023/png/1635081/1687064581905-a44c5746-a5a9-4a0d-8c4b-892b597d92da.png#averageHue=%23fbf9f8&clientId=u492e267b-d925-4&from=paste&id=u6267ab7a&originHeight=45&originWidth=506&originalType=url&ratio=0.800000011920929&rotation=0&showTitle=false&status=done&style=none&taskId=uc3844de3-eec7-4ff4-a1e6-7b639affe66&title=)<br />如果内存中想要存入所有的 url，共需要 50 亿 \* 64= 320G 大小空间，所以采用 hash 分解+<br />分而治之 + 归并 的方式：<br />（1）f 分别遍历文件 a，b ， 以 a 为例 ： 对每个 url 根据某种 hash 规则，求取 hash(url)/1024，然后根据所取得的值将 url 分别存储到 1024 个小文件（a0~a1023）中。这样每个小文件的大约为 300M。<br />如果 hash 结果很集中使得某个文件 ai 过大，可以在对 ai 进行二级 hash(ai0~ai1024)，这样 url 就 被 hash 到 1024 个不同级别的文件中。<br />（2）分别比较 ab 各自对应的文件，a0 VS b0，…… ，a1023 VS b1023，求每对小文件中相同的 url 时：<br />把其中一个小文件的 url 存储到 hashmap 中，然后遍历另一个小文件的每个 url，看其是否<br />在刚才构建的 hashmap 中，如果是，那么就是共同的 url，存到文件中。<br />（3）把 1024 个文件中的相同 url 合并起来<br />![image.png](https://cdn.nlark.com/yuque/0/2023/png/1635081/1687064581936-79c414f8-7456-4978-ae25-7ff3e04da6d2.png#averageHue=%23fcfcfb&clientId=u492e267b-d925-4&from=paste&id=u52f12be5&originHeight=48&originWidth=531&originalType=url&ratio=0.800000011920929&rotation=0&showTitle=false&status=done&style=none&taskId=u408678a1-59f0-4642-af19-a6c4a9cad67&title=)<br />如果允许有一定的错误率，可以使用 Bloom filter，4G 内存大概可以表示 340 亿 bit，n = 50 亿，如果按照出错率 0.01 算需要的大概是 650 亿个 bit，现在可用的是 340 亿，相差并不多，这样可能会使出错率上升些，将其中一个文件中的 url 使用 Bloom filter 映射为这 340 亿 bit，然后挨个读取另外一个文件的 url，检查是否与 Bloom filter，如果是，那么该 url 应该是共同的 url（注意会有一定的错误率）
<a name="N4qRo"></a>

## 问题 4：有 10 个文件，每个文件 1G，每个文件的每一行存放的都是用户的 query，每个文件的 query 都可能重复。要求你按照 query 的频度排序。

解决方案 1：hash 分解+ 分而治之 +归并<br />（1）顺序读取 10 个文件 a0~a9，按照 hash(query)%10 的结果将 query 写入到另外 10 个文件（记为 b0~b9）中，这样新生成的文件每个的大小大约也 1G<br />（2）找一台内存 2G 左右的机器，依次使用 hashmap(query, query_count) 来统计每个 query 出现的次数。利用 快速/堆/[归并排序](https://so.csdn.net/so/search?q=%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F&spm=1001.2101.3001.7020) 按照出现次数进行排序。将排序好的 query 和对应的 query_cout 输出到文件中。这样得到了 10 个排好序的文件 c0~c9。<br />（3）对这 10 个文件 c0~c9 进行归并排序（内排序与外排序相结合）。每次取 c0~c9 文件的 m 个数据放到内存中，进行 10m 个数据的归并，即使把归并好的数据存到 d 结果文件中。如果 ci 对应的 m 个数据全归并完了，再从 ci 余下的数据中取 m 个数据重新加载到内存中。直到所有 ci 文件的所有数据全部归并完成。<br />解决方案 2：Trie 树<br />如果 query 的总量是有限的，只是重复的次数比较多而已，可能对于所有的 query，一次性<br />就可以加入到内存了。在这种情况下，可以采用 trie 树/hashmap 等直接来统计每个 query 出<br />现的次数，然后按出现次数做快速/堆/归并排序就可以了。
<a name="KfOU4"></a>

## 问题 5：海量数据分布在 100 台电脑中，请高效统计出这批数据的 TOP10

解决思想： 分而治之 + 归并<br />（1）在每台电脑上求出 TOP10，采用包含 10 个元素的堆完成（TOP10 小，用最大堆，<br />TOP10 大，用最小堆）<br />（2）求出每台电脑上的 TOP10 后，把这 100 台电脑上的 TOP10 合并之后，共 1000 个数<br />据，在采用堆排序或者快排方式 求出 top10<br />（注意：该题的 TOP10 是取最大值或最小值，如果取频率 TOP10，就应该先 hash 分解，<br />将相同的数据移动到同一台电脑中，再使用 hashmap 分别统计出现的频率）
<a name="VmEfY"></a>

## 问题 6：在 2.5 亿个整数中找出不重复的整数，内存不足以容纳这 2.5 亿个整数

解决方案 1：hash 分解+ 分而治之 + 归并<br />（1）2.5 亿个 int 类型 hash 到 1024 个小文件中 a0~a1023，如果某个小文件大小还大于内存，进行多级 hash<br />（2）将每个小文件读进内存，找出只出现一次的数据，输出到 b0~b1023<br />（3）最后数据合并即可<br />解决方案 2 ： 2-Bitmap<br />如果内存够 1GB 的话，采用 2-Bitmap 进行统计，共需内存 2^32 \* 2bit = 1GB 内存。<br />2- bitmap 中，每个数分配 2bit（00 表示不存在，01 表示出现一次，10 表示多次，11 无意义），<br />然后扫描这 2.5 亿个整数，查看 Bitmap 中相对应位，如果是 00，则将其置为 01；如果是 01，将其置为 10；如果是 10，则保持不变。所描完成后，查看 bitmap，把对应位是 01 的整数输出即可。<br />（如果是找出重复的数据，可以用 1-bitmap。第一次 bit 位由 0 变 1，第二次查询到相应 bit 位为 1 说明是重复数据，输出即可）
